







.version 7.6
.target sm_75
.address_size 64


.extern .func (.param .b32 func_retval0) vprintf
(
.param .b64 vprintf_param_0,
.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 $str[27] = {45, 45, 45, 115, 116, 97, 114, 116, 45, 45, 45, 116, 97, 114, 103, 101, 116, 45, 45, 45, 115, 112, 45, 45, 45, 10, 0};
.global .align 1 .b8 $str$1[62] = {45, 45, 45, 101, 110, 100, 45, 45, 45, 116, 97, 114, 103, 101, 116, 45, 45, 45, 115, 112, 45, 45, 32, 97, 82, 111, 119, 58, 32, 37, 100, 44, 32, 97, 67, 111, 108, 58, 32, 37, 100, 44, 32, 98, 82, 111, 119, 58, 32, 37, 100, 44, 32, 98, 67, 111, 108, 58, 37, 100, 10, 0};
.global .align 1 .b8 $str$2[69] = {45, 45, 45, 45, 115, 116, 97, 114, 116, 45, 45, 116, 97, 114, 103, 101, 116, 45, 45, 45, 116, 101, 110, 115, 111, 114, 45, 45, 58, 32, 97, 82, 111, 119, 58, 32, 37, 100, 44, 32, 97, 67, 111, 108, 58, 32, 37, 100, 44, 32, 98, 82, 111, 119, 58, 32, 37, 100, 44, 32, 98, 67, 111, 108, 58, 37, 100, 10, 0};
.global .align 1 .b8 $str$3[29] = {45, 45, 45, 101, 110, 100, 45, 45, 45, 116, 97, 114, 103, 101, 116, 45, 45, 45, 116, 101, 110, 115, 111, 114, 45, 45, 45, 10, 0};

.visible .entry _Z12wmma_exampleP6__halfS0_Pfiiiff(
.param .u64 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_0,
.param .u64 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_1,
.param .u64 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_2,
.param .u32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_3,
.param .u32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_4,
.param .u32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_5,
.param .f32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_6,
.param .f32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_7
)
{
.local .align 16 .b8 __local_depot0[16];
.reg .b64 %SP;
.reg .b64 %SPL;
.reg .pred %p<15>;
.reg .f32 %f<254>;
.reg .b32 %r<203>;
.reg .b64 %rd<97>;


mov.u64 %SPL, __local_depot0;
cvta.local.u64 %SP, %SPL;
ld.param.u64 %rd9, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_0];
ld.param.u64 %rd10, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_1];
ld.param.u32 %r47, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_3];
ld.param.u32 %r49, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_4];
ld.param.u32 %r48, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_5];
cvta.to.global.u64 %rd1, %rd9;
mov.u32 %r50, %ntid.x;
mov.u32 %r51, %ctaid.x;
mov.u32 %r52, %tid.x;
mad.lo.s32 %r53, %r51, %r50, %r52;
mov.u32 %r54, %ntid.y;
mov.u32 %r55, %ctaid.y;
mov.u32 %r56, WARP_SZ;
div.u32 %r57, %r53, %r56;
mov.u32 %r58, %tid.y;
mad.lo.s32 %r59, %r55, %r54, %r58;
cvta.to.global.u64 %rd3, %rd10;
shl.b32 %r1, %r57, 4;
shl.b32 %r2, %r59, 4;
setp.lt.s32 %p2, %r1, %r47;
setp.lt.s32 %p3, %r2, %r49;
and.pred %p1, %p3, %p2;
setp.lt.s32 %p4, %r48, 1;
mov.f32 %f189, 0f00000000;
mov.f32 %f188, %f189;
mov.f32 %f187, %f189;
mov.f32 %f186, %f189;
mov.f32 %f185, %f189;
mov.f32 %f184, %f189;
mov.f32 %f183, %f189;
mov.f32 %f182, %f189;
@%p4 bra $L__BB0_17;

add.u64 %rd12, %SP, 0;
add.u64 %rd4, %SPL, 0;
mul.lo.s32 %r3, %r2, %r48;
add.s32 %r61, %r48, -1;
shr.u32 %r62, %r61, 4;
add.s32 %r4, %r62, 1;
and.b32 %r5, %r4, 3;
setp.lt.u32 %p5, %r61, 48;
mov.u32 %r60, 0;
mov.f32 %f182, 0f00000000;
mov.f32 %f183, %f182;
mov.f32 %f184, %f182;
mov.f32 %f185, %f182;
mov.f32 %f186, %f182;
mov.f32 %f187, %f182;
mov.f32 %f188, %f182;
mov.f32 %f189, %f182;
mov.u32 %r198, %r60;
@%p5 bra $L__BB0_12;

sub.s32 %r197, %r4, %r5;
mov.u64 %rd13, $str;
cvta.global.u64 %rd14, %rd13;
mov.u64 %rd15, 0;
mov.u64 %rd16, $str$1;
cvta.global.u64 %rd17, %rd16;
not.pred %p6, %p1;

$L__BB0_3:
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd14;
.param .b64 param1;
st.param.b64 [param1+0], %rd15;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r65, [retval0+0];
} 
	mov.u32 %r202, %r60;
st.local.v4.u32 [%rd4], {%r1, %r198, %r198, %r2};
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd17;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r69, [retval0+0];
} 
	@%p6 bra $L__BB0_5;

st.local.v4.u32 [%rd4], {%r1, %r198, %r198, %r2};
mov.u64 %rd20, $str$2;
cvta.global.u64 %rd21, %rd20;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd21;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r70, [retval0+0];
} 
	mad.lo.s32 %r71, %r198, %r47, %r1;
mul.wide.s32 %rd23, %r71, 2;
add.s64 %rd24, %rd1, %rd23;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r72, %r73, %r74, %r75, %r76, %r77, %r78, %r79}, [%rd24], %r47;
add.s32 %r80, %r198, %r3;
mul.wide.s32 %rd25, %r80, 2;
add.s64 %rd26, %rd3, %rd25;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r81, %r82, %r83, %r84, %r85, %r86, %r87, %r88}, [%rd26], %r48;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r72, %r73, %r74, %r75, %r76, %r77, %r78, %r79}, {%r81, %r82, %r83, %r84, %r85, %r86, %r87, %r88}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd27, $str$3;
cvta.global.u64 %rd28, %rd27;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd28;
.param .b64 param1;
st.param.b64 [param1+0], %rd15;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r89, [retval0+0];
} 

$L__BB0_5:
mov.u32 %r90, 0;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd14;
.param .b64 param1;
st.param.b64 [param1+0], %rd15;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r91, [retval0+0];
} 
	mov.u32 %r202, %r90;
add.s32 %r20, %r198, 16;
st.local.v4.u32 [%rd4], {%r1, %r20, %r20, %r2};
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd17;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r92, [retval0+0];
} 
	@%p6 bra $L__BB0_7;

add.s32 %r183, %r198, 16;
st.local.v4.u32 [%rd4], {%r1, %r183, %r20, %r2};
mov.u64 %rd36, $str$2;
cvta.global.u64 %rd37, %rd36;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd37;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r93, [retval0+0];
} 
	mad.lo.s32 %r94, %r20, %r47, %r1;
mul.wide.s32 %rd39, %r94, 2;
add.s64 %rd40, %rd1, %rd39;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r95, %r96, %r97, %r98, %r99, %r100, %r101, %r102}, [%rd40], %r47;
add.s32 %r103, %r20, %r3;
mul.wide.s32 %rd41, %r103, 2;
add.s64 %rd42, %rd3, %rd41;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r104, %r105, %r106, %r107, %r108, %r109, %r110, %r111}, [%rd42], %r48;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r95, %r96, %r97, %r98, %r99, %r100, %r101, %r102}, {%r104, %r105, %r106, %r107, %r108, %r109, %r110, %r111}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd43, $str$3;
cvta.global.u64 %rd44, %rd43;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd44;
.param .b64 param1;
st.param.b64 [param1+0], %rd15;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r112, [retval0+0];
} 

$L__BB0_7:
mov.u32 %r186, 0;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd14;
.param .b64 param1;
st.param.b64 [param1+0], %rd15;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r114, [retval0+0];
} 
	mov.u32 %r202, %r186;
add.s32 %r25, %r198, 32;
st.local.v4.u32 [%rd4], {%r1, %r25, %r25, %r2};
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd17;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r115, [retval0+0];
} 
	@%p6 bra $L__BB0_9;

add.s32 %r184, %r198, 32;
st.local.v4.u32 [%rd4], {%r1, %r184, %r25, %r2};
mov.u64 %rd52, $str$2;
cvta.global.u64 %rd53, %rd52;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd53;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r116, [retval0+0];
} 
	mad.lo.s32 %r117, %r25, %r47, %r1;
mul.wide.s32 %rd55, %r117, 2;
add.s64 %rd56, %rd1, %rd55;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r118, %r119, %r120, %r121, %r122, %r123, %r124, %r125}, [%rd56], %r47;
add.s32 %r126, %r25, %r3;
mul.wide.s32 %rd57, %r126, 2;
add.s64 %rd58, %rd3, %rd57;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r127, %r128, %r129, %r130, %r131, %r132, %r133, %r134}, [%rd58], %r48;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r118, %r119, %r120, %r121, %r122, %r123, %r124, %r125}, {%r127, %r128, %r129, %r130, %r131, %r132, %r133, %r134}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd59, $str$3;
cvta.global.u64 %rd60, %rd59;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd60;
.param .b64 param1;
st.param.b64 [param1+0], %rd15;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r135, [retval0+0];
} 

$L__BB0_9:
mov.u32 %r187, 0;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd14;
.param .b64 param1;
st.param.b64 [param1+0], %rd15;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r137, [retval0+0];
} 
	mov.u32 %r202, %r187;
add.s32 %r30, %r198, 48;
st.local.v4.u32 [%rd4], {%r1, %r30, %r30, %r2};
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd17;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r138, [retval0+0];
} 
	@%p6 bra $L__BB0_11;

add.s32 %r185, %r198, 48;
st.local.v4.u32 [%rd4], {%r1, %r185, %r30, %r2};
mov.u64 %rd68, $str$2;
cvta.global.u64 %rd69, %rd68;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd69;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r139, [retval0+0];
} 
	mad.lo.s32 %r140, %r30, %r47, %r1;
mul.wide.s32 %rd71, %r140, 2;
add.s64 %rd72, %rd1, %rd71;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r141, %r142, %r143, %r144, %r145, %r146, %r147, %r148}, [%rd72], %r47;
add.s32 %r149, %r30, %r3;
mul.wide.s32 %rd73, %r149, 2;
add.s64 %rd74, %rd3, %rd73;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r150, %r151, %r152, %r153, %r154, %r155, %r156, %r157}, [%rd74], %r48;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r141, %r142, %r143, %r144, %r145, %r146, %r147, %r148}, {%r150, %r151, %r152, %r153, %r154, %r155, %r156, %r157}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd75, $str$3;
cvta.global.u64 %rd76, %rd75;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd76;
.param .b64 param1;
st.param.b64 [param1+0], %rd15;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r158, [retval0+0];
} 

$L__BB0_11:
add.s32 %r198, %r198, 64;
add.s32 %r197, %r197, -4;
setp.ne.s32 %p10, %r197, 0;
@%p10 bra $L__BB0_3;

$L__BB0_12:
add.s32 %r191, %r48, -1;
shr.u32 %r190, %r191, 4;
add.s32 %r189, %r190, 1;
and.b32 %r188, %r189, 3;
setp.eq.s32 %p11, %r188, 0;
@%p11 bra $L__BB0_17;

add.s32 %r195, %r48, -1;
shr.u32 %r194, %r195, 4;
add.s32 %r193, %r194, 1;
and.b32 %r201, %r193, 3;
add.s32 %r159, %r198, %r3;
mul.wide.s32 %rd77, %r159, 2;
add.s64 %rd96, %rd3, %rd77;
mul.lo.s32 %r199, %r198, %r47;
shl.b32 %r36, %r47, 4;
mov.u64 %rd78, $str;
cvta.global.u64 %rd79, %rd78;
mov.u64 %rd80, 0;
not.pred %p12, %p1;

$L__BB0_14:
.pragma "nounroll";
mov.u32 %r160, 0;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd79;
.param .b64 param1;
st.param.b64 [param1+0], %rd80;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r161, [retval0+0];
} 
	mov.u32 %r202, %r160;
st.local.v4.u32 [%rd4], {%r1, %r198, %r198, %r2};
mov.u64 %rd81, $str$1;
cvta.global.u64 %rd82, %rd81;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd82;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r162, [retval0+0];
} 
	@%p12 bra $L__BB0_16;

st.local.v4.u32 [%rd4], {%r1, %r198, %r198, %r2};
mov.u64 %rd85, $str$2;
cvta.global.u64 %rd86, %rd85;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd86;
.param .b64 param1;
st.param.b64 [param1+0], %rd12;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r163, [retval0+0];
} 
	add.s32 %r164, %r199, %r1;
mul.wide.s32 %rd88, %r164, 2;
add.s64 %rd89, %rd1, %rd88;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r165, %r166, %r167, %r168, %r169, %r170, %r171, %r172}, [%rd89], %r47;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r173, %r174, %r175, %r176, %r177, %r178, %r179, %r180}, [%rd96], %r48;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r165, %r166, %r167, %r168, %r169, %r170, %r171, %r172}, {%r173, %r174, %r175, %r176, %r177, %r178, %r179, %r180}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd90, $str$3;
cvta.global.u64 %rd91, %rd90;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd91;
.param .b64 param1;
st.param.b64 [param1+0], %rd80;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r181, [retval0+0];
} 

$L__BB0_16:
add.s32 %r198, %r198, 16;
add.s64 %rd96, %rd96, 32;
add.s32 %r199, %r199, %r36;
add.s32 %r201, %r201, -1;
setp.ne.s32 %p13, %r201, 0;
@%p13 bra $L__BB0_14;

$L__BB0_17:
not.pred %p14, %p1;
@%p14 bra $L__BB0_19;

ld.param.f32 %f173, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_6];
ld.param.f32 %f172, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_7];
ld.param.u64 %rd95, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_2];
cvta.to.global.u64 %rd92, %rd95;
mad.lo.s32 %r182, %r2, %r47, %r1;
mul.wide.s32 %rd93, %r182, 4;
add.s64 %rd94, %rd92, %rd93;
wmma.load.c.sync.aligned.col.m16n16k16.global.f32 {%f148, %f149, %f150, %f151, %f152, %f153, %f154, %f155}, [%rd94], %r47;
mul.f32 %f156, %f148, %f172;
fma.rn.f32 %f157, %f189, %f173, %f156;
mul.f32 %f158, %f149, %f172;
fma.rn.f32 %f159, %f188, %f173, %f158;
mul.f32 %f160, %f150, %f172;
fma.rn.f32 %f161, %f187, %f173, %f160;
mul.f32 %f162, %f151, %f172;
fma.rn.f32 %f163, %f186, %f173, %f162;
mul.f32 %f164, %f152, %f172;
fma.rn.f32 %f165, %f185, %f173, %f164;
mul.f32 %f166, %f153, %f172;
fma.rn.f32 %f167, %f184, %f173, %f166;
mul.f32 %f168, %f154, %f172;
fma.rn.f32 %f169, %f183, %f173, %f168;
mul.f32 %f170, %f155, %f172;
fma.rn.f32 %f171, %f182, %f173, %f170;
wmma.store.d.sync.aligned.col.m16n16k16.global.f32 [%rd94], {%f157, %f159, %f161, %f163, %f165, %f167, %f169, %f171}, %r47;

$L__BB0_19:
ret;

}

.visible .entry _Z17convertFp32ToFp16P6__halfPfi(
.param .u64 _Z17convertFp32ToFp16P6__halfPfi_param_0,
.param .u64 _Z17convertFp32ToFp16P6__halfPfi_param_1,
.param .u32 _Z17convertFp32ToFp16P6__halfPfi_param_2
)
{
.reg .pred %p<2>;
.reg .b16 %rs<2>;
.reg .f32 %f<2>;
.reg .b32 %r<6>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z17convertFp32ToFp16P6__halfPfi_param_0];
ld.param.u64 %rd2, [_Z17convertFp32ToFp16P6__halfPfi_param_1];
ld.param.u32 %r2, [_Z17convertFp32ToFp16P6__halfPfi_param_2];
mov.u32 %r3, %ntid.x;
mov.u32 %r4, %ctaid.x;
mov.u32 %r5, %tid.x;
mad.lo.s32 %r1, %r3, %r4, %r5;
setp.ge.s32 %p1, %r1, %r2;
@%p1 bra $L__BB1_2;

cvta.to.global.u64 %rd3, %rd2;
mul.wide.s32 %rd4, %r1, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f1, [%rd5];

	{ cvt.rn.f16.f32 %rs1, %f1;}


	cvta.to.global.u64 %rd6, %rd1;
mul.wide.s32 %rd7, %r1, 2;
add.s64 %rd8, %rd6, %rd7;
st.global.u16 [%rd8], %rs1;

$L__BB1_2:
ret;

}


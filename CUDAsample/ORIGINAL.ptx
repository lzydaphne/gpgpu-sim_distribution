







.version 7.6
.target sm_75
.address_size 64


.extern .func (.param .b32 func_retval0) vprintf
(
.param .b64 vprintf_param_0,
.param .b64 vprintf_param_1
)
;
.global .align 1 .b8 $str[26] = {45, 45, 45, 45, 115, 116, 97, 114, 116, 45, 45, 116, 97, 114, 103, 101, 116, 45, 45, 45, 115, 112, 45, 45, 10, 0};
.global .align 1 .b8 $str$1[24] = {45, 45, 45, 101, 110, 100, 45, 45, 45, 116, 97, 114, 103, 101, 116, 45, 45, 45, 115, 112, 45, 45, 10, 0};
.global .align 1 .b8 $str$2[30] = {45, 45, 45, 45, 115, 116, 97, 114, 116, 45, 45, 116, 97, 114, 103, 101, 116, 45, 45, 45, 116, 101, 110, 115, 111, 114, 45, 45, 10, 0};
.global .align 1 .b8 $str$3[28] = {45, 45, 45, 101, 110, 100, 45, 45, 45, 116, 97, 114, 103, 101, 116, 45, 45, 45, 116, 101, 110, 115, 111, 114, 45, 45, 10, 0};

.visible .entry _Z12wmma_exampleP6__halfS0_Pfiiiff(
.param .u64 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_0,
.param .u64 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_1,
.param .u64 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_2,
.param .u32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_3,
.param .u32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_4,
.param .u32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_5,
.param .f32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_6,
.param .f32 _Z12wmma_exampleP6__halfS0_Pfiiiff_param_7
)
{
.reg .pred %p<15>;
.reg .f32 %f<254>;
.reg .b32 %r<167>;
.reg .b64 %rd<83>;


ld.param.u64 %rd7, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_0];
ld.param.u64 %rd8, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_1];
ld.param.u32 %r18, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_3];
ld.param.u32 %r20, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_4];
ld.param.u32 %r19, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_5];
cvta.to.global.u64 %rd1, %rd7;
mov.u32 %r21, %ntid.x;
mov.u32 %r22, %ctaid.x;
mov.u32 %r23, %tid.x;
mad.lo.s32 %r24, %r22, %r21, %r23;
mov.u32 %r25, %ntid.y;
mov.u32 %r26, %ctaid.y;
mov.u32 %r27, WARP_SZ;
div.u32 %r28, %r24, %r27;
mov.u32 %r29, %tid.y;
mad.lo.s32 %r30, %r26, %r25, %r29;
cvta.to.global.u64 %rd2, %rd8;
shl.b32 %r1, %r28, 4;
shl.b32 %r2, %r30, 4;
setp.lt.s32 %p2, %r1, %r18;
setp.lt.s32 %p3, %r2, %r20;
and.pred %p1, %p3, %p2;
setp.lt.s32 %p4, %r19, 1;
mov.f32 %f189, 0f00000000;
mov.f32 %f188, %f189;
mov.f32 %f187, %f189;
mov.f32 %f186, %f189;
mov.f32 %f185, %f189;
mov.f32 %f184, %f189;
mov.f32 %f183, %f189;
mov.f32 %f182, %f189;
@%p4 bra $L__BB0_17;

mul.lo.s32 %r3, %r2, %r19;
add.s32 %r32, %r19, -1;
shr.u32 %r33, %r32, 4;
add.s32 %r4, %r33, 1;
and.b32 %r5, %r4, 3;
setp.lt.u32 %p5, %r32, 48;
mov.u32 %r164, 0;
mov.f32 %f182, 0f00000000;
mov.f32 %f183, %f182;
mov.f32 %f184, %f182;
mov.f32 %f185, %f182;
mov.f32 %f186, %f182;
mov.f32 %f187, %f182;
mov.f32 %f188, %f182;
mov.f32 %f189, %f182;
@%p5 bra $L__BB0_12;

sub.s32 %r163, %r4, %r5;
mov.u64 %rd9, $str;
cvta.global.u64 %rd10, %rd9;
mov.u64 %rd11, 0;
mov.u64 %rd12, $str$1;
cvta.global.u64 %rd13, %rd12;
not.pred %p6, %p1;
mov.u64 %rd14, $str$2;
cvta.global.u64 %rd15, %rd14;

$L__BB0_3:
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd10;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r35, [retval0+0];
} 
	{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd13;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r36, [retval0+0];
} 
	@%p6 bra $L__BB0_5;

{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd15;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r37, [retval0+0];
} 
	mad.lo.s32 %r38, %r164, %r18, %r1;
mul.wide.s32 %rd17, %r38, 2;
add.s64 %rd18, %rd1, %rd17;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r39, %r40, %r41, %r42, %r43, %r44, %r45, %r46}, [%rd18], %r18;
add.s32 %r47, %r164, %r3;
mul.wide.s32 %rd19, %r47, 2;
add.s64 %rd20, %rd2, %rd19;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r48, %r49, %r50, %r51, %r52, %r53, %r54, %r55}, [%rd20], %r19;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r39, %r40, %r41, %r42, %r43, %r44, %r45, %r46}, {%r48, %r49, %r50, %r51, %r52, %r53, %r54, %r55}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd21, $str$3;
cvta.global.u64 %rd22, %rd21;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd22;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r56, [retval0+0];
} 

$L__BB0_5:
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd10;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r57, [retval0+0];
} 
	{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd13;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r58, [retval0+0];
} 
	@%p6 bra $L__BB0_7;

add.s32 %r59, %r164, 16;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd15;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r60, [retval0+0];
} 
	mad.lo.s32 %r61, %r59, %r18, %r1;
mul.wide.s32 %rd31, %r61, 2;
add.s64 %rd32, %rd1, %rd31;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r62, %r63, %r64, %r65, %r66, %r67, %r68, %r69}, [%rd32], %r18;
add.s32 %r70, %r59, %r3;
mul.wide.s32 %rd33, %r70, 2;
add.s64 %rd34, %rd2, %rd33;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r71, %r72, %r73, %r74, %r75, %r76, %r77, %r78}, [%rd34], %r19;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r62, %r63, %r64, %r65, %r66, %r67, %r68, %r69}, {%r71, %r72, %r73, %r74, %r75, %r76, %r77, %r78}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd35, $str$3;
cvta.global.u64 %rd36, %rd35;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd36;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r79, [retval0+0];
} 

$L__BB0_7:
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd10;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r80, [retval0+0];
} 
	{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd13;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r81, [retval0+0];
} 
	@%p6 bra $L__BB0_9;

add.s32 %r82, %r164, 32;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd15;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r83, [retval0+0];
} 
	mad.lo.s32 %r84, %r82, %r18, %r1;
mul.wide.s32 %rd45, %r84, 2;
add.s64 %rd46, %rd1, %rd45;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r85, %r86, %r87, %r88, %r89, %r90, %r91, %r92}, [%rd46], %r18;
add.s32 %r93, %r82, %r3;
mul.wide.s32 %rd47, %r93, 2;
add.s64 %rd48, %rd2, %rd47;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r94, %r95, %r96, %r97, %r98, %r99, %r100, %r101}, [%rd48], %r19;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r85, %r86, %r87, %r88, %r89, %r90, %r91, %r92}, {%r94, %r95, %r96, %r97, %r98, %r99, %r100, %r101}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd49, $str$3;
cvta.global.u64 %rd50, %rd49;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd50;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r102, [retval0+0];
} 

$L__BB0_9:
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd10;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r103, [retval0+0];
} 
	{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd13;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r104, [retval0+0];
} 
	@%p6 bra $L__BB0_11;

add.s32 %r105, %r164, 48;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd15;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r106, [retval0+0];
} 
	mad.lo.s32 %r107, %r105, %r18, %r1;
mul.wide.s32 %rd59, %r107, 2;
add.s64 %rd60, %rd1, %rd59;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r108, %r109, %r110, %r111, %r112, %r113, %r114, %r115}, [%rd60], %r18;
add.s32 %r116, %r105, %r3;
mul.wide.s32 %rd61, %r116, 2;
add.s64 %rd62, %rd2, %rd61;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r117, %r118, %r119, %r120, %r121, %r122, %r123, %r124}, [%rd62], %r19;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r108, %r109, %r110, %r111, %r112, %r113, %r114, %r115}, {%r117, %r118, %r119, %r120, %r121, %r122, %r123, %r124}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd63, $str$3;
cvta.global.u64 %rd64, %rd63;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd64;
.param .b64 param1;
st.param.b64 [param1+0], %rd11;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r125, [retval0+0];
} 

$L__BB0_11:
add.s32 %r164, %r164, 64;
add.s32 %r163, %r163, -4;
setp.ne.s32 %p10, %r163, 0;
@%p10 bra $L__BB0_3;

$L__BB0_12:
add.s32 %r157, %r19, -1;
shr.u32 %r156, %r157, 4;
add.s32 %r155, %r156, 1;
and.b32 %r154, %r155, 3;
setp.eq.s32 %p11, %r154, 0;
@%p11 bra $L__BB0_17;

add.s32 %r161, %r19, -1;
shr.u32 %r160, %r161, 4;
add.s32 %r159, %r160, 1;
and.b32 %r166, %r159, 3;
add.s32 %r126, %r164, %r3;
mul.wide.s32 %rd65, %r126, 2;
add.s64 %rd82, %rd2, %rd65;
mul.lo.s32 %r165, %r164, %r18;
shl.b32 %r13, %r18, 4;
mov.u64 %rd66, $str;
cvta.global.u64 %rd67, %rd66;
mov.u64 %rd68, 0;
not.pred %p12, %p1;

$L__BB0_14:
.pragma "nounroll";
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd67;
.param .b64 param1;
st.param.b64 [param1+0], %rd68;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r127, [retval0+0];
} 
	mov.u64 %rd69, $str$1;
cvta.global.u64 %rd70, %rd69;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd70;
.param .b64 param1;
st.param.b64 [param1+0], %rd68;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r128, [retval0+0];
} 
	@%p12 bra $L__BB0_16;

mov.u64 %rd71, $str$2;
cvta.global.u64 %rd72, %rd71;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd72;
.param .b64 param1;
st.param.b64 [param1+0], %rd68;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r129, [retval0+0];
} 
	add.s32 %r130, %r165, %r1;
mul.wide.s32 %rd74, %r130, 2;
add.s64 %rd75, %rd1, %rd74;
wmma.load.a.sync.aligned.col.m16n16k16.global.f16 {%r131, %r132, %r133, %r134, %r135, %r136, %r137, %r138}, [%rd75], %r18;
wmma.load.b.sync.aligned.col.m16n16k16.global.f16 {%r139, %r140, %r141, %r142, %r143, %r144, %r145, %r146}, [%rd82], %r19;
wmma.mma.sync.aligned.col.col.m16n16k16.f32.f32 {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182}, {%r131, %r132, %r133, %r134, %r135, %r136, %r137, %r138}, {%r139, %r140, %r141, %r142, %r143, %r144, %r145, %r146}, {%f189, %f188, %f187, %f186, %f185, %f184, %f183, %f182};
mov.u64 %rd76, $str$3;
cvta.global.u64 %rd77, %rd76;
{ 
	.reg .b32 temp_param_reg;
.param .b64 param0;
st.param.b64 [param0+0], %rd77;
.param .b64 param1;
st.param.b64 [param1+0], %rd68;
.param .b32 retval0;
call.uni (retval0), 
vprintf, 
(
param0, 
param1
);
ld.param.b32 %r147, [retval0+0];
} 

$L__BB0_16:
add.s64 %rd82, %rd82, 32;
add.s32 %r165, %r165, %r13;
add.s32 %r166, %r166, -1;
setp.ne.s32 %p13, %r166, 0;
@%p13 bra $L__BB0_14;

$L__BB0_17:
not.pred %p14, %p1;
@%p14 bra $L__BB0_19;

ld.param.f32 %f173, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_6];
ld.param.f32 %f172, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_7];
ld.param.u64 %rd81, [_Z12wmma_exampleP6__halfS0_Pfiiiff_param_2];
mov.u32 %r153, %tid.y;
mov.u32 %r152, %ntid.y;
mov.u32 %r151, %ctaid.y;
mad.lo.s32 %r150, %r151, %r152, %r153;
shl.b32 %r149, %r150, 4;
cvta.to.global.u64 %rd78, %rd81;
mad.lo.s32 %r148, %r149, %r18, %r1;
mul.wide.s32 %rd79, %r148, 4;
add.s64 %rd80, %rd78, %rd79;
wmma.load.c.sync.aligned.col.m16n16k16.global.f32 {%f148, %f149, %f150, %f151, %f152, %f153, %f154, %f155}, [%rd80], %r18;
mul.f32 %f156, %f148, %f172;
fma.rn.f32 %f157, %f189, %f173, %f156;
mul.f32 %f158, %f149, %f172;
fma.rn.f32 %f159, %f188, %f173, %f158;
mul.f32 %f160, %f150, %f172;
fma.rn.f32 %f161, %f187, %f173, %f160;
mul.f32 %f162, %f151, %f172;
fma.rn.f32 %f163, %f186, %f173, %f162;
mul.f32 %f164, %f152, %f172;
fma.rn.f32 %f165, %f185, %f173, %f164;
mul.f32 %f166, %f153, %f172;
fma.rn.f32 %f167, %f184, %f173, %f166;
mul.f32 %f168, %f154, %f172;
fma.rn.f32 %f169, %f183, %f173, %f168;
mul.f32 %f170, %f155, %f172;
fma.rn.f32 %f171, %f182, %f173, %f170;
wmma.store.d.sync.aligned.col.m16n16k16.global.f32 [%rd80], {%f157, %f159, %f161, %f163, %f165, %f167, %f169, %f171}, %r18;

$L__BB0_19:
ret;

}

.visible .entry _Z17convertFp32ToFp16P6__halfPfi(
.param .u64 _Z17convertFp32ToFp16P6__halfPfi_param_0,
.param .u64 _Z17convertFp32ToFp16P6__halfPfi_param_1,
.param .u32 _Z17convertFp32ToFp16P6__halfPfi_param_2
)
{
.reg .pred %p<2>;
.reg .b16 %rs<2>;
.reg .f32 %f<2>;
.reg .b32 %r<6>;
.reg .b64 %rd<9>;


ld.param.u64 %rd1, [_Z17convertFp32ToFp16P6__halfPfi_param_0];
ld.param.u64 %rd2, [_Z17convertFp32ToFp16P6__halfPfi_param_1];
ld.param.u32 %r2, [_Z17convertFp32ToFp16P6__halfPfi_param_2];
mov.u32 %r3, %ntid.x;
mov.u32 %r4, %ctaid.x;
mov.u32 %r5, %tid.x;
mad.lo.s32 %r1, %r3, %r4, %r5;
setp.ge.s32 %p1, %r1, %r2;
@%p1 bra $L__BB1_2;

cvta.to.global.u64 %rd3, %rd2;
mul.wide.s32 %rd4, %r1, 4;
add.s64 %rd5, %rd3, %rd4;
ld.global.f32 %f1, [%rd5];

	{ cvt.rn.f16.f32 %rs1, %f1;}


	cvta.to.global.u64 %rd6, %rd1;
mul.wide.s32 %rd7, %r1, 2;
add.s64 %rd8, %rd6, %rd7;
st.global.u16 [%rd8], %rs1;

$L__BB1_2:
ret;

}

